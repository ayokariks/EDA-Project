---
title: "Ranger Random Forest For South Korean Energy Consumption(Heat)"
output: html_notebook
Author: "Ayokunle Arikawe"
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

```{r}
#import all the libraries
library(tidyverse)
library(caret)
library(rpart)
library(broom)
library(rpart)
library(randomForest)
library(ranger)
library(e1071)


```
```{r}
#read data and convert categrory columns to factors

train_full <- read_csv('C:/Users/Admin/EDA-Project/data/sKor_train_data.csv')

train_full <- train_full %>% mutate(across(starts_with("cat"), as.factor))
summary(train_full)

```



```{r}
#cross validation with validation data

#ensure you discuss that random forest isnnot intutative.


train_sample <- sample(nrow(train_full), 0.02*nrow(train_full), replace = FALSE)

training_sample<- train_full[train_sample,]
#set sequence for the 3 hyper parameters
num_tree<- seq(250,2000,50)
min_nodes <- seq(2,10,2)
m_try <- seq(4,18,2)
split_rule <- c("variance", "extratrees", "maxstat")


#add all hyparemeters to one grid
ranger_grid <-  expand.grid( splitrule=split_rule,
                         #num.trees = num_tree, 
                        mtry  = m_try,
                        min.node.size = min_nodes)



#set the train cross validation
tr_Control <- trainControl(method = "cv",
    number = 10,
    search = "grid")

#measure the run time of the hyparameters
start_time <- Sys.time()
#traim mpodel with hypeparameters using grid serch and 10 fold cross validation
set.seed(123)
ranger_modelfit <- train(num_tot_energy_heat ~ ., data = train_full, 
                 method = "ranger", 
                 trControl = tr_Control,
                 verbose = FALSE, 
                 tuneGrid = ranger_grid)
end_time <- Sys.time()

time_elapse <- end_time - start_time

time_elapse
#1.4105 hours
#best model from cv
#ranger_modelfit$bestTune
#get_best_result(ranger_best_model)
ranger_best_model <- best(ranger_modelfit$results, metric = "RMSE",  maximize = TRUE)
ranger_modelfit$results[ranger_best_model, 1:6]


#varImpPlot()
#ways to get the best results

#get_best_result

#best model based on results with the importance measured on variance of sreponses and sum 
test_full <- read_csv('C:/Users/Admin/EDA-Project/data/sKor_test_data.csv')

test_full <- test_full %>% mutate(across(starts_with("cat"), as.factor))

ranger_model_best <- ranger(num_tot_energy_heat~., data=test_full,splitrule="maxstat",
                        importance = "impurity",
                        mtry  = 4,
                        min.node.size = 10)

ranger_model_best

#used to plot the importance chat of each varaibles
varImpPlot(ranger_model_best)



#maxstat	2	10	5139.151

#importance(ranger_test)

#ranger random forest with no hyperparmeters
#ranger_basic <- ranger(num_tot_energy_heat~., data=training_sample)

#importance 



```
```{r}

#mightry randomsearchaswell and see computational difference samesteps as grid search
```
```{r}
#visualise to compare the different models
trellis.par.set(caretTheme())
plot(ranger_modelfit) 

#
ggplot(ranger_modelfit)

#residuals vs predicted
#predicted vs actual

#Variable importance chart where possible.
i#mportance_features
```
```{r}

#predictions based on the model choosen with training data

predictions <- predict(ranger_model_best, test_full, type = 'response')

#compare actual to predicted

test_preds <- test_full%>% 
  transmute(
        actual = num_tot_energy_heat,
        predicted_ranger=predictions$predictions)

#rmsee
rmse <- function(actual, predicted){
  mse <- mean((actual - predicted) ** 2)
  return(sqrt(mse))
}

mse <- function(actual, predicted){
  mse <- mean((actual - predicted) ** 2)
  return((mse))
}

mae <- function(actual, predicted){
  mae <- mean((actual - predicted))
  return((mae))
}

final_predictions <- test_preds  %>% mutate(
  rmse=rmse(actual,predicted_ranger),
  mse=mse(actual,predicted_ranger),                          mae=mae(actual,predicted_ranger))

final_predictions <- final_predictions %>% 
  mutate(residual = predicted_ranger - actual)

library(ggplot2)
#true_value and trednline
final_predictions %>% 
  ggplot(aes(x = actual, y = residual)) + 
  geom_point() + 
  geom_smooth(method = 'lm') 

#true_value and trednline
final_predictions %>% 
  ggplot(aes(x = predicted_ranger, y = residual)) + 
  geom_point() + 
  geom_smooth(method = 'lm') 

#Prediction vs True value 
final_predictions %>% 
  ggplot(aes(x = predicted_ranger, y = actual)) + 
  geom_point() + 
  geom_smooth(method = 'lm') 


#importance plot

#ggplot(visualization)

importance_features <- ranger_model_best$variable.importance

importance_features

export_preds <- final_predictions%>% 
  transmute(
        actual = actual,
        predictions=predicted_ranger,
        residual = residual)

#export predictions

write.csv(export_preds,"C:/Users/Admin/EDA-Project/data/ayo_test_random_forest.csv")



```



Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
