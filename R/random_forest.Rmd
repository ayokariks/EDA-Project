---
title: "R Notebook"
output: html_notebook
Author: "Ayokunle Arikawe"
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

```{r}
library(tidyverse)
library(caret)
library(rpart)
library(broom)
library(rpart)
library(randomForest)
# bring in data and inspect data
#make category (factors)
df <- read_csv("C:/Users/Admin/EDA-Project/data/sKor_data_tot_v02.csv")

df <- df %>% mutate(across(starts_with("cat"), as.factor))
summary(df)

```
```{r}
#EDA ad # initial Feature Engineering
#for continuous to numeric e.g the total energy consumption to num_of_households do boxplots

#for categorical data can utilise heat map to see relationship


```

```{r}
#seed split(train-test 70:30)

#
#train: 70 train: 30 validation
set.seed(100)
train <- sample(nrow(df), 0.7*nrow(df), replace = FALSE)
training_set<- df[train,]
testing_set <- df[-train,]


train_rf <- sample(nrow(df), 0.1*nrow(df), replace = FALSE)
train_rf_set <- df[train_rf,]
        
#basic Random Forest train and fit

RFM <- randomForest(num_tot_energy_heat~., data=training_set)

predictions <- predict(RFM,training_set, type = 'response')


#evaluations of predictions
train_predictions <- training_set%>%
  transmute(
        actual = num_tot_energy_heat,
        predicted = predictions
        )


rmse <- function(actual, predicted){
  mse <- mean((actual - predicted) ** 2)
  return(sqrt(mse))
}


predictions <- train_predictions %>% mutate(rmse=rmse(actual,predicted), difference = actual-predicted) 


#hyper parameters: ntree and mtry(number of features to do), add importance = TRUE



```

```{r}
#cross validation with validation data
#ensure you discuss that random forest isnnot intutative.

library(e1071)
#k-fold cross validatio
trcontrol <- trainControl(method = "cv", number = 10,search="grid")


set.seed(100)

rf_default <- train(num_tot_energy_heat~.,
                    data = train_rf_set,
                    method = "ranger",
                    metric = "RMSE",
                    trcontrol = trcontrol
                    )

#Hyparametrise  umber of features to subset(mtry)

#rf_default <- train()




```
```{r}
#search for best mtry(1:18)
#run them at same time(mtry, ntree, maxnodes)
#add the sequence 
tuneGrid <- expand.grid(.mtry = c(1: 18))
rf_mtry <- train(num_tot_energy_heat~,
    data = training_set,
    method = "rf",
    metric = "RMSE",
    tuneGrid = tuneGrid,
    trcontrol = trcontrol,
    importance = TRUE,
    nodesize = 14,
    ntree = 300)
print(rf_mtry)

#best value for mtry based on best RMSE
best_mtry <- rf_mtry$bestTune$mtry
```

```{r}
#search best max nodes
store_maxnode <- list()
tuneGrid <- expand.grid(.mtry = best_mtry)
for (maxnodes in c(5: 15)) {
    rf_maxnode <- train(num_tot_energy_heat~.,
        data = training_set,
        method = "rf",
        metric = "RMSE",
        tuneGrid = tuneGrid,
        trcontrol = trcontrol,
        importance = TRUE,
        nodesize = n,
        maxnodes = maxnodes,
        ntree =n)
    current_iteration <- toString(maxnodes)
    store_maxnode[[current_iteration]] <- rf_maxnode
}
results_mtry <- resamples(store_maxnode)
summary(results_mtry)
#SELECTMAX node
```

```{r}
#search best ntrees
store_maxtrees <- list()
for (ntree in c(250, 300, 350, 400, 450, 500, 550, 600, 800, 1000, 2000)) {
    set.seed(5678)
    rf_maxtrees <- train(num_tot_energy_heat~.,
        data = training_set,
        method = "rf",
        metric = "RMSE",
        tuneGrid = tuneGrid,
        trcontrol = trcontrol,
        importance = TRUE,
        nodesize = n,
        maxnodes = n,
        ntree = ntree)
    key <- toString(ntree)
    store_maxtrees[[key]] <- rf_maxtrees
}
results_tree <- resamples(store_maxtrees)
summary(results_tree)

```
```{r}
#final model with hyparameters
fit_rf <- train(num_tot_energy_heat~.,
    data_train,
    method = "rf",
    metric = "RMSE",
    tuneGrid = tuneGrid,
    trcontrol = trcontrol,
    importance = TRUE,
    nodesize = n,
    ntree = n,
    maxnodes = n)

```
```{r}
#evalutate model, importance and residuals

predictions <- predict(fit_rf, training_set, type = 'response')

#importance of certain features
varImpPlot(fit_rf)

#plot residuals

train_predictions <- TrainSet%>%
  transmute(
        actual = num_tot_energy_heat,
        predicted = predictions
        )


rmse <- function(actual, predicted){
  mse <- mean((actual - predicted) ** 2)
  return(sqrt(mse))
}


predictions <- train_predictions %>% mutate(rmse=rmse(actual,predicted), difference = actual-predicted) 

TrainSet <- TrainSet %>% 
  mutate(residual = predictions - num_tot_energy_heat)

#y axis rmse, r2,  x axis, vs complexity of random forest) similar to k means

```


Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
