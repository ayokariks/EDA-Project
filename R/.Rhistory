library(gutenbergr)
library(tidytext)
options(digits = 3)
gutenberg_metadata
data("gutenberg_metadata")
str_detect(gutenberg_metadata$title, "Pride and Prejudice")
sum(str_detect(gutenberg_metadata$title, "Pride and Prejudice"))
sum(str_detect(gutenberg_metadata$title, "Pride and Prejudice") na.rm = TRUE)
sum(str_detect(gutenberg_metadata$title, "Pride and Prejudice"), na.rm = TRUE)
gutenberg_metadata %>%
filter(str_detect(title, "Pride and Prejudice"))
?gutenberg_works
gutenberg_works(title = "Pride and Prejudice")
gutenberg_works(title == "Pride and Prejudice")
gutenberg_download(1342)
library(tidytext)
pnp <- gutenberg_download(1342)
pnp %>% unnest_tokens(pnp, word, text)
example <- data_frame(line = c(1, 2, 3, 4),
text = c("Roses are red,", "Violets are blue,", "Sugar is sweet,", "And so are you."))
example
example %>% unnest_tokens(word, text)
View(pnp)
words <- unnest_tokens(pnp, word, text
words <- unnest_tokens(pnp, word, text)
words <- unnest_tokens(pnp, word, text)
words2 <- words %>% filter(!word %in% stop_words$word)
View(words2)
nonum <- "\\d"
words3 <- words2 %>% filter(!str_detect(word, "\\d"))
words3 %>% count(word)
words3 %>% count(word) %>% arrange(desc(n))
words3 %>% count(word) %>% filter(n > 100)
words3 %>%
count(word) %>%
top_n(1, n) %>%
pull(n)
afinn <- get_sentiments("afinn")
Yes
install.packages("textdata")
library(textdata)
afinn <- get_sentiments("afinn")
afinn_sentiments <- inner_join(afinn, by = "word")
afinn_sentiments <- words3 %>% inner_join(afinn, by = "word")
View(afinn)
View(afinn_sentiments)
afinn_sentiments %>% filter(value > 0) %>% pull(value) %>% sum()
afinn_sentiments %>% filter(value > 0) %>% pull(value) %>% count()
afinn_sentiments %>% filter(value > 0) %>% pull(value) %>% nrows()
afinn_sentiments %>% filter(value > 0) %>% pull(value) %>% nrow()
afinn_sentiments %>% filter(value > 0)
afinn_sentiments %>% filter(value > 0) %>% nrow()
afinn_sentiments %>% filter(value == 4) %>% nrow()
afinn_sentiments %>% filter(value >= 1) %>% nrow()
3414/6065
library(pdftools)
options(digits = 3)
install.packages("pdftools")
library(pdftools)
fn <- system.file("extdata", "RD-Mortality-Report_2015-18-180531.pdf", package="dslabs")
system("cmd.exe", input = paste("start", fn))
txt <- pdf_text(fn)
x <- txt[[9]] %>% str_split("\\n")
View(x)
View(x)
View(x)
x
s <- x[[1]]
s <- s %>% str_trim(side = "both")
s[[1]]
header_index <- str_which(s, "2015")
header_index
header_index <- header_index[[1]]
header_index
header <- s[[3]]
header %>% str_split("\\s+")
header %>% str_split("\\s+" simplify = TRUE)
header %>% str_split("\\s+", simplify = TRUE)
month <- header %>% str_split("\\s+", simplify = TRUE)[1]
month <- str_split(header, "\\s+", simplify = TRUE)[1]
header <- str_split(header, "\\s+", simplify = TRUE)[-1]
s
total_index <- 36
tail_index <- total_index
n <- str_count(s, "\\d+")
filter(n, n == "1")
n
s <- str_remove(s, header_index)
out <- c(1:header_index, which(n==1), tail_index:length(s))
s <- s[-out]
s <- str_remove_all(s, "[^\\d]")
s <- str_remove_all(s, "[^\\d\\s]")
s <- x[[1]]
s <- str_trim(s)
s <- s[-out]
s <- str_remove_all(s, "[^\\d\\s]")
s <- str_split_fixed(s, "\\s+", n = 6)[,1:5]
View(s)
setNames(s = c("day", "header", "header", "header", "header"))
names(s) <- c("day", "header", "header", "header", "header")
View(s)
View(s)
names(s) <- c("day", "header", "header", "header", "header")
View(s)
setNames(s, c("day", "header", "header", "header", "header"))
View(s)
View(s)
names(s) <- c("day", "header", "header", "header", "header")
s
s <- x[[1]]
s <- str_trim(s)
s <- s[-out]
s <- str_remove_all(s, "[^\\d\\s]")
s <- str_split_fixed(s, "\\s+", n = 6)[,1:5]
View(s)
s
as.numeric(s)
tab <- names(s, c("day", "2015", "2016", "2017", "2018")) %>% as.numeric() %>% mutate(month = "Sep")
class(S)
class(s)
colnames(s) <- c("day", header)
s
tab <- as.numeric(s)
tab
st <- s %>% mutate(month = month)
tab %>% mutate(month = month)
View(s)
mean(s$2015)
mean(s[2])
s[2]
s[2,2]
tab[2,2]
tab <- s %>%
as_data_frame() %>%
mutate_all(as.numeric)
View(tab)
library(Lahman)
library(tidyverse)
library(dslabs)
ds_theme_set()
library(tidyverse)
library(ggplot2)
library(HistData)
data("GaltonFamilies")
galton_heights <- GaltonFamilies %>%
filter(gender == "male") %>%
group_by(family) %>%
sample_n(1) %>%
ungroup() %>%
select(father, childHeight) %>%
rename(son = childHeight)
beta1 = seq(0, 1, len=nrow(galton_heights))
results <- data.frame(beta1 = beta1,
rss = sapply(beta1, rss, beta0 = 36))
results %>% ggplot(aes(beta1, rss)) + geom_line() +
geom_line(aes(beta1, rss), col=2)
rss <- function(beta0, beta1){
resid <- galton_heights$son - (beta0+beta1*galton_heights$father)
return(sum(resid^2))
}
beta1 = seq(0, 1, len=nrow(galton_heights))
results <- data.frame(beta1 = beta1,
rss = sapply(beta1, rss, beta0 = 36))
results %>% ggplot(aes(beta1, rss)) + geom_line() +
geom_line(aes(beta1, rss), col=2)
library(Lahman)
data("Teams")
model <- lm(son ~ father, data = galton_heights)
predictions <- predict(model, interval = c("confidence"), level = 0.95)
data <- as.tibble(predictions) %>% bind_cols(father = galton_heights$father)
ggplot(data, aes(x = father, y = fit)) +
geom_line(color = "blue", size = 1) +
geom_ribbon(aes(ymin=lwr, ymax=upr), alpha=0.2) +
geom_point(data = galton_heights, aes(x = father, y = son))
model <- lm(son ~ father, data = galton_heights)
predictions <- predict(model)
data <- as.tibble(predictions) %>% bind_cols(father = galton_heights$father)
ggplot(data, aes(x = father, y = fit)) +
geom_line(color = "blue", size = 1) +
geom_point(data = galton_heights, aes(x = father, y = son))
teamsf <- Teams %>% filter(yearID %in% 1961:2001)
teams_beta1 = seq(0, 1, len=nrow(teamsf))
?do
teamsf%>%
mutate(R_per_game = R/G, BB_per_game = BB/G, HR_per_game = HR/G) %>% summariselm(R_per_game ~ BB_per_game + HR_per_game, data = .))
teamsf%>%
mutate(R_per_game = R/G, BB_per_game = BB/G, HR_per_game = HR/G) %>% summarise(lm(R_per_game ~ BB_per_game + HR_per_game, data = .))
set.seed(1989, sample.kind="Rounding") #if you are using R 3.6 or later
library(HistData)
data("GaltonFamilies")
options(digits = 3)
female_heights <- GaltonFamilies %>%
filter(gender == "female") %>%
group_by(family) %>%
sample_n(1) %>%
ungroup() %>%
select(mother, childHeight) %>%
rename(daughter = childHeight)
female_heights %>% lm(mother ~ daughter)
lm(mother ~ daughter, data = female_heights)
View(female_heights)
0.31(69) + 44.18
0.31*(69) + 44.18
fit <- lm(mother ~ daughter, data = female_heights)
predict(fit)[1]
library(Lahman)
bat_02 <- Batting %>% filter(yearID == 2002) %>%
mutate(pa = AB + BB, singles = (H - X2B - X3B - HR)/pa, bb = BB/pa) %>%
filter(pa >= 100) %>%
select(playerID, singles, bb)
library(Lahman)
bat_99 <- Batting %>% filter(yearID %in% 1999:2001) %>%
mutate(pa = AB + BB, singles = (H - X2B - X3B - HR)/pa, bb = BB/pa) %>%
filter(pa >= 100) %>%
select(playerID, singles, bb)
View(bat_99)
bat_99 %>% filter(singles > 0.2) %>% nrow()
bat_99 %>% filter(bb > 0.2) %>% nrow()
bat_99 %>% filter(singles > 0.2) %>% group_by(playerID)
bat_99 %>% filter(bb > 0.2) %>% group_by(playerID)
bat_99 %>% filter(singles >0.2) %>% group_by(playerID) %>% summarise(mean_singles = mean(singles))
bat_99 %>% summarise(mean_singles = mean(singles)) %>% filter(mean_singles >0.2) %>% group_by(playerID)
bat_99 %>% group_by(playerID) %>% summarise(mean_singles = mean(singles)) %>% filter(mean_singles >0.2)
bat_99 %>% group_by(playerID) %>% summarise(mean_bb = mean(bb)) %>% filter(mean_bb >0.2)
bat_99_01 <- Batting %>% filter(yearID %in% 1999:2001) %>%
mutate(pa = AB + BB, singles = (H - X2B - X3B - HR)/pa, bb = BB/pa) %>%
filter(pa >= 100) %>%
group_by(playerID) %>%
summarize(mean_singles = mean(singles), mean_bb = mean(bb))
sum(bat_99_01$mean_singles > 0.2)
View(bat_99_01)
inner_join(bat_99_01, bat_02, by = "playerID")
bat_99_02 <- inner_join(bat_99_01, bat_02, by = "playerID")
View(bat_99_02)
bat_99_02 %>% cor(singles, mean_singles)
bat_99_02 %>% summarize(r = cor(mean_singles, singles)) %>% pull(r)
bat_99_02 %>% summarize(r = cor(mean_bb, bb)) %>% pull(r)
bat_99_02 %>% ggplot(aes(singles, mean_singles)) + geom_point()
bat_99_02 %>% ggplot(aes(bb, mean_bb)) + geom_point()
lm(singles ~ mean_singles data = bat_99_02)
lm(singles ~ mean_singles, data = bat_99_02)
lm(bb ~ mean_bb, data = bat_99_02)
?do
dat <- Teams %>% filter(yearID %in% 1961:2001) %>%
mutate(HR = round(HR/G, 1),
BB = BB/G,
R = R/G) %>%
select(HR, BB, R) %>%
filter(HR >= 0.4 & HR<=1.2)
dat2 <- dat %>% group_by(HR)
View(dat2)
View(dat)
lm (R ~ BB, data = dat2)
dat %>% do(fit2 = lm(R ~ BB, data = .))
library(broom)
set.seed(1, sample.kind = "Rounding") # if you are using R 3.6 or later
galton <- GaltonFamilies %>%
group_by(family, gender) %>%
sample_n(1) %>%
ungroup() %>%
gather(parent, parentHeight, father:mother) %>%
mutate(child = ifelse(gender == "female", "daughter", "son")) %>%
unite(pair, c("parent", "child"))
galton %>% group_by(heights)
galton %>% group_by(pair)
View(galton)
galton %>% group_by(pair) %>% filter(pair == "father_daughter")
galton %>% group_by(pair) %>% filter(pair == "mother_son")
galton %>%
group_by(pair) %>%
summarize(n = n())
galton %>% group_by(pair) %>% summarize(r = cor(parentHeight, childHeight)) %>% pull(r)
galton %>% group_by(pair) %>% summarize(r = cor(parentHeight, childHeight))
galton %>%
group_by(pair) %>%
do(tidy(lm(childHeight ~ parentHeight, data = .), conf.int = T))
galton_grouped <- galton %>% group_by(pair) %>% do(tidy(lm(childHeight ~ parentHeight, data = .), conf.int = T))
View(galton_grouped)
67*0.381+44.878
68*0.381+44.878
fit <- Teams %>%
filter(yearID == 1971) %>%
mutate(BB = BB/G, HR = HR/G,  R = R/G) %>%
lm(R ~ BB + HR, data = .)
tidy(fit, conf.int = TRUE)
bat_71 <- tidy(fit, conf.int = TRUE)
View(bat_71)
fit3 <- Teams %>%
+     filter(yearID %in% 1961:2018) %>%
+     mutate(BB = BB/G, HR = HR/G,  R = R/G) %>%
+     lm(R ~ BB + HR, data = .)
> tidy(fit3, conf.int = TRUE)
Q10 <- Teams %>% filter(yearID %in% 1961:2018) %>% mutate(BB = BB/G, HR = HR/G,  R = R/G) %>% group_by(yearID) %>% do(lm(R ~ HR + BB, data = .))
Q10 <- Teams %>% filter(yearID %in% 1961:2018) %>% mutate(BB = BB/G, HR = HR/G,  R = R/G) %>% group_by(yearID) %>% do(tidy(lm(R ~ HR + BB, data = .)))
View(Q10)
Q10 %>% filter(term == "BB") %>% ggplot(aes(yearID, estimate)) + geom_point()
res <- Teams %>%
filter(yearID %in% 1961:2018) %>%
group_by(yearID) %>%
do(tidy(lm(R ~ BB + HR, data = .))) %>%
ungroup()
res %>%
filter(term == "BB") %>%
ggplot(aes(yearID, estimate)) +
geom_point() +
geom_smooth(method = "lm")
lm(BB ~ yearID, data = Q10)
lm(BB ~ yearID, data = res)
lm(estimate ~ yearID, data = res)
predict(lm(estimate ~ yearID, data = res))
?lm
Q11 <- Teams %>% filter(yearID %in% 1961:2018) %>%group_by(yearID) %>% do(tidy(lm(R ~ BB + HR, data = .))) %>% filter(term == "BB") %>% lm(estimate ~ yearID, data = .)
View(Q11)
lm(estimate ~ yearID, data = res)
View(res)
Q11 res %>% filter(term == "BB") %>% lm(estimate ~ yearID, data = .)
Q11 <- res %>% filter(term == "BB") %>% lm(estimate ~ yearID, data = .)
View(Q11)
Q11
summary(Q11)
Teams_small <- Teams %>%
filter(yearID %in% 1961:2001) %>%
mutate(avg_attendance = attendance/G)
lm(avg_attendance ~ R, data = Teams_small)
lm(avg_attendance ~ HR, data = Teams_small)
mutate(Teams_small, R_per_game = R/G, HR_per_game = HR/G)
Teams_small <- mutate(Teams_small, R_per_game = R/G, HR_per_game = HR/G)
lm(avg_attendance ~ HR_per_game, data = Teams_small)
lm(formula = avg_attendance ~ R_per_game, data = Teams_small)
lm(average_attendance ~ W, data = Teams_small)
lm(avg_attendance ~ W, data = Teams_small)
lm(avg_attendance ~ yearID, data = Teams_small)
lm(avg_attendance ~ W + R_per_game, data = Teams_small)
cor(Teams_small$W, Teams_small$R_per_game)
cor(Teams_small$W, Teams_small$HR_per_game)
Teams_strat <- Teams_small %>% mutate(win_strat = round(W/10, digits = 0)) %>% filter(win_strat %in% 5:10 & n >= 20)
Teams_strat <- Teams_small %>% mutate(win_strat = round(W/10, digits = 0)) %>%
Teams_strat <- Teams_small %>% mutate(win_strat = round(W/10, digits = 0))
Teams_strat <- Teams_small %>% mutate(win_strat = round(W/10, digits = 0))
View(Teams_strat)
Teams_strat <- Teams_strat %>% filter(win_strat >= 5 & <= 10 )
Teams_strat <- Teams_strat %>% filter(win_strat >= 5 & win_strat <= 10)
Teams_strat <- Teams_strat %>% group_by(teamID) %>% filter(n() >= 20)
Teams_strat %>% filter(win_strat == 8) %>% nrow()
Teams_strat <- Teams_strat %>% group_by(teamID)
Teams_strat <- Teams_strat %>% group_by(teamID) %>% filter(n() >= 20)
Teams_strat <- Teams_strat %>% group_by(name) %>% filter(n() >= 20)
?group_by()
Teams_strat %>% filter(win_strat == 8) %>% nrow()
Teams_strat <- Teams_small %>% mutate(win_strat = round(W/10, digits = 0)) %>% group_by(teamID) %>% filter(win_strat >= 5 & <= 10 )
Teams_strat <- Teams_small %>% mutate(win_strat = round(W/10, digits = 0)) %>% group_by(teamID) %>% filter(win_strat >= 5 & win_strat <= 10 )
Teams_strat <- Teams_small %>% mutate(win_strat = round(W/10, digits = 0)) %>% group_by(teamID) %>% filter(n() >= 20) %>% filter(win_strat >= 5 & win_strat <= 10)
eight_strat <- Teams_strat %>% filter(win_strat == 8) %>% filter(n() >= 20)
View(eight_strat)
eight_strat <- Teams_strat %>% filter(win_strat == 8)
eight_strat <- Teams_strat %>% filter(win_strat == 8) %>% filter(n(teamID) >= 20)
eight_strat <- Teams_strat %>% filter(win_strat == 8) %>% filter(n(teamID()) >= 20)
eight_strat <- Teams_strat %>% filter(win_strat == 8) %>% filter(teamID, n() >= 20)
eight_strat <- Teams_strat %>% filter(win_strat == 8) %>% group_by(teamID) %>% filter(n() >= 20)
View(Teams_strat)
Teams_strat <- Teams_small %>% mutate(win_strat = round(W/10, digits = 0)) %>% filter(win_strat >= 5 & win_strat <= 10) %>% group_by(teamID) %>% filter(n() >= 20)
eight_strat <- Teams_strat %>% filter(win_strat == 8) %>% group_by(teamID) %>%
l
eight_strat <- Teams_strat %>% filter(win_strat == 8) %>% group_by(teamID)
eight_strat <- Teams_strat %>% filter(win_strat == 8 & W >= 20)
Teams_strat <- Teams_small %>% mutate(win_strat = round(W/10, digits = 0)) %>% filter(win_strat >= 5 & win_strat <= 10)
eight_strat <- Teams_strat %>% filter(win_strat == 8) %>% nrow()
eight_strat <- Teams_strat %>% filter(win_strat == 8)
eight_strat %>% group_by(win_strat) %>% lm(avg_attendance ~ R_per_game, data = .)
Teams_strat %>% group_by(win_strat) %>% lm(avg_attendance ~ R_per_game, data = .)
Teams_strat %>% group_by(win_strat)
Teams_strat <- Teams_small %>% mutate(win_strat = round(W/10, digits = 0)) %>% filter(win_strat >= 5 & win_strat <= 10)
Teams_strat %>%
ggplot(aes(R_per_game, avg_attendance)) +
geom_point(alpha = 0.5) +
geom_smooth(method = "lm") +
facet_wrap( ~ win_strat)
Teams_strat %>%
ggplot(aes(HR_per_game, avg_attendance)) +  geom_point(alpha = 0.5) + geom_smooth(method = "lm") + facet_wrap( ~ win_strat)
Teams_strat <- Teams_small %>% mutate(win_strat = round(W/10, digits = 0)) %>% filter(win_strat >= 5 & win_strat <= 10)
> Teams_strat %>% ggplot(aes(R_per_game, avg_attendance)) +  geom_point(alpha = 0.5) + geom_smooth(method = "lm") + facet_wrap( ~ win_strat)
Teams_strat %>% ggplot(aes(R_per_game, avg_attendance)) +  geom_point(alpha = 0.5) + geom_smooth(method = "lm") + facet_wrap( ~ win_strat)
lm(avg_attendance ~ R_per_game + HR_per_game + W + yearID, data = Teams_small)
?fit
fit <- lm(avg_attendance ~ R_per_game + HR_per_game + W + yearID, data = Teams_small)
?predict
predict(fit, newdata = c(5, 1.2, 80, 2002))
newlist <- c(5, 1.2, 80, 2002)
class(newlist)
predict(fit, newdata = newlist)
data.frame(c(5, 1.2, 80, 2002))
data.frame(
speed = c(12, 19, 24)
)
newlist1 <- data.frame(R_per_game = 5, HR_per_game = 1.2, W = 80, yearID = 2002)
View(newlist1)
predict(fit, newdata = newlist1)
newlist2 <- data.frame(R_per_game = 5, HR_per_game = 1.2, W = 80, yearID = 1960)
predict(fit, newdata = newlist2)
predict(fit, Teams)
Teams %>% mutate(R_per_game = R/G, HR_per_game = HR/G, avg_attendance = attendance/G) %>% predict(fit, newdata = .)
Teams %>% mutate(R_per_game = R/G, HR_per_game = HR/G, avg_attendance = attendance/G) %>% filter(yearID == 2002) %>% predict(fit, newdata = .)
Teams %>% mutate(R_per_game = R/G, HR_per_game = HR/G, avg_attendance = attendance/G) %>% filter(yearID == 2002) %>% mutate(predicted = predict(fit, newdata = .)) %>% summarize(r = cor(avg_attendance, predicted))
library(broom)
install.packages("pROC")
install.packages(c('spData', 'spDataLarge', 'tmap', 'leaflet'))
library(sf)
library(raster)
library(dplyr)
library(tmap)
library(leaflet)
library(ggplot2)
library(raster)
# Tosin's code for prepping, training, and testing
# SKor Data
setwd("~/R/UCL/BENV0091/EDA-Project/EDA-Project/R")
library(tidyverse)
library(rpart) # for regression trees
library(caret) # for splitting into train and test sets
df <- read_csv("../data/sKor_data_tot_v02.csv")
excluded_vars <- c("X1", "id_hs", "id_hh") #removing IDs so I can comfortably use (.)
df <- df %>% dplyr::select(-excluded_vars)
# r said to use `all_of(excluded_vars)` to silence warning but
# it worked sooo
set.seed(123)
train_index <- createDataPartition(df$num_tot_energy_heat, times = 1,
p = 0.7, list = FALSE)
train <- df %>% slice(train_index)
test <- df %>% slice(-train_index)
train_rpart <- train(num_tot_energy_heat ~ .,
method = "rpart",
tuneGrid = data.frame(cp = seq(0, 0.05, len = 25)),
data = train)
best_cp <- train_rpart$bestTune
View(best_cp)
hyper_grid <- expand.grid(
minsplit = seq(20, 60, 1),
maxdepth = seq(30, 60, 1)
)
#setting up a for loop to iterate through each minsplit and maxdepth
#combination
models <- list()
for (i in 1:nrow(hyper_grid)) {
# get minsplit, maxdepth values at row i
minsplit <- hyper_grid$minsplit[i]
maxdepth <- hyper_grid$maxdepth[i]
# train a model and store in the list
models[[i]] <- rpart(
formula = num_tot_energy_heat ~ .,
data    = train,
control = list(minsplit = minsplit, maxdepth = maxdepth)
)
}
View(models)
# function to get optimal cp
get_cp <- function(x) {
min    <- which.min(x$cptable[, "xerror"])
cp <- x$cptable[min, "CP"]
}
# function to get minimum error
get_min_error <- function(x) {
min    <- which.min(x$cptable[, "xerror"])
xerror <- x$cptable[min, "xerror"]
}
hyper_grid %>%
mutate(
cp    = purrr::map_dbl(models, get_cp),
error = purrr::map_dbl(models, get_min_error)
) %>%
arrange(error) %>%
top_n(-5, wt = error)
min    <- which.min(train_rpart$cptable[, "xerror"])
xerror <- train_rpart$cptable[min, "xerror"]
view(train_rpart)
View(train_rpart)
train_rpart[["finalModel"]][["cptable"]]
plot(train_rpart$finalModel)
plot(train_rpart$finalModel, margin = 0.1)
text(train_rpart$finalModel, cex = 0.75)
head(df)
?across
df <- df %>% select(starts_with("Sepal")) %>%  mutate(across(where(is.numeric), as.factor))
View(df)
df <- read_csv("../data/sKor_data_tot_v02.csv")
excluded_vars <- c("X1", "id_hs", "id_hh") #removing IDs so I can comfortably use (.)
df <- df %>% dplyr::select(-excluded_vars)
df <- df %>% select(starts_with("cat")) %>%  mutate(across(where(is.numeric), as.factor))
View(df)
head(df)
df <- read_csv("../data/sKor_data_tot_v02.csv")
df <- df %>% dplyr::select(-excluded_vars)
df <- df %>%  mutate(across(where((starts_with("cat"))), as.factor))
df <- df %>% mutate(across(starts_with("cat"), as.factor))
View(df)
head(df)
set.seed(123)
train_index <- createDataPartition(df$num_tot_energy_heat, times = 1,
p = 0.7, list = FALSE)
#meant to create partition on the y values, as it stratifies that data
train <- df %>% slice(train_index)
test <- df %>% slice(-train_index)
train_rpart <- train(num_tot_energy_heat ~ .,
method = "rpart",
tuneGrid = data.frame(cp = seq(0, 0.05, len = 25)),
data = train)
best_cp <- train_rpart$bestTune
view(best_cp)
train_rpart[["finalModel"]][["cptable"]]
plot(train_rpart$finalModel, margin = 0.1)
text(train_rpart$finalModel, cex = 0.75)
plot(train_rpart$finalModel, margin = 0.1)
text(train_rpart$finalModel, cex = 0.75)
