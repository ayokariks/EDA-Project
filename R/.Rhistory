View(s)
setNames(s, c("day", "header", "header", "header", "header"))
View(s)
View(s)
names(s) <- c("day", "header", "header", "header", "header")
s
s <- x[[1]]
s <- str_trim(s)
s <- s[-out]
s <- str_remove_all(s, "[^\\d\\s]")
s <- str_split_fixed(s, "\\s+", n = 6)[,1:5]
View(s)
s
as.numeric(s)
tab <- names(s, c("day", "2015", "2016", "2017", "2018")) %>% as.numeric() %>% mutate(month = "Sep")
class(S)
class(s)
colnames(s) <- c("day", header)
s
tab <- as.numeric(s)
tab
st <- s %>% mutate(month = month)
tab %>% mutate(month = month)
View(s)
mean(s$2015)
mean(s[2])
s[2]
s[2,2]
tab[2,2]
tab <- s %>%
as_data_frame() %>%
mutate_all(as.numeric)
View(tab)
library(Lahman)
library(tidyverse)
library(dslabs)
ds_theme_set()
library(tidyverse)
library(ggplot2)
library(HistData)
data("GaltonFamilies")
galton_heights <- GaltonFamilies %>%
filter(gender == "male") %>%
group_by(family) %>%
sample_n(1) %>%
ungroup() %>%
select(father, childHeight) %>%
rename(son = childHeight)
beta1 = seq(0, 1, len=nrow(galton_heights))
results <- data.frame(beta1 = beta1,
rss = sapply(beta1, rss, beta0 = 36))
results %>% ggplot(aes(beta1, rss)) + geom_line() +
geom_line(aes(beta1, rss), col=2)
rss <- function(beta0, beta1){
resid <- galton_heights$son - (beta0+beta1*galton_heights$father)
return(sum(resid^2))
}
beta1 = seq(0, 1, len=nrow(galton_heights))
results <- data.frame(beta1 = beta1,
rss = sapply(beta1, rss, beta0 = 36))
results %>% ggplot(aes(beta1, rss)) + geom_line() +
geom_line(aes(beta1, rss), col=2)
library(Lahman)
data("Teams")
model <- lm(son ~ father, data = galton_heights)
predictions <- predict(model, interval = c("confidence"), level = 0.95)
data <- as.tibble(predictions) %>% bind_cols(father = galton_heights$father)
ggplot(data, aes(x = father, y = fit)) +
geom_line(color = "blue", size = 1) +
geom_ribbon(aes(ymin=lwr, ymax=upr), alpha=0.2) +
geom_point(data = galton_heights, aes(x = father, y = son))
model <- lm(son ~ father, data = galton_heights)
predictions <- predict(model)
data <- as.tibble(predictions) %>% bind_cols(father = galton_heights$father)
ggplot(data, aes(x = father, y = fit)) +
geom_line(color = "blue", size = 1) +
geom_point(data = galton_heights, aes(x = father, y = son))
teamsf <- Teams %>% filter(yearID %in% 1961:2001)
teams_beta1 = seq(0, 1, len=nrow(teamsf))
?do
teamsf%>%
mutate(R_per_game = R/G, BB_per_game = BB/G, HR_per_game = HR/G) %>% summariselm(R_per_game ~ BB_per_game + HR_per_game, data = .))
teamsf%>%
mutate(R_per_game = R/G, BB_per_game = BB/G, HR_per_game = HR/G) %>% summarise(lm(R_per_game ~ BB_per_game + HR_per_game, data = .))
set.seed(1989, sample.kind="Rounding") #if you are using R 3.6 or later
library(HistData)
data("GaltonFamilies")
options(digits = 3)
female_heights <- GaltonFamilies %>%
filter(gender == "female") %>%
group_by(family) %>%
sample_n(1) %>%
ungroup() %>%
select(mother, childHeight) %>%
rename(daughter = childHeight)
female_heights %>% lm(mother ~ daughter)
lm(mother ~ daughter, data = female_heights)
View(female_heights)
0.31(69) + 44.18
0.31*(69) + 44.18
fit <- lm(mother ~ daughter, data = female_heights)
predict(fit)[1]
library(Lahman)
bat_02 <- Batting %>% filter(yearID == 2002) %>%
mutate(pa = AB + BB, singles = (H - X2B - X3B - HR)/pa, bb = BB/pa) %>%
filter(pa >= 100) %>%
select(playerID, singles, bb)
library(Lahman)
bat_99 <- Batting %>% filter(yearID %in% 1999:2001) %>%
mutate(pa = AB + BB, singles = (H - X2B - X3B - HR)/pa, bb = BB/pa) %>%
filter(pa >= 100) %>%
select(playerID, singles, bb)
View(bat_99)
bat_99 %>% filter(singles > 0.2) %>% nrow()
bat_99 %>% filter(bb > 0.2) %>% nrow()
bat_99 %>% filter(singles > 0.2) %>% group_by(playerID)
bat_99 %>% filter(bb > 0.2) %>% group_by(playerID)
bat_99 %>% filter(singles >0.2) %>% group_by(playerID) %>% summarise(mean_singles = mean(singles))
bat_99 %>% summarise(mean_singles = mean(singles)) %>% filter(mean_singles >0.2) %>% group_by(playerID)
bat_99 %>% group_by(playerID) %>% summarise(mean_singles = mean(singles)) %>% filter(mean_singles >0.2)
bat_99 %>% group_by(playerID) %>% summarise(mean_bb = mean(bb)) %>% filter(mean_bb >0.2)
bat_99_01 <- Batting %>% filter(yearID %in% 1999:2001) %>%
mutate(pa = AB + BB, singles = (H - X2B - X3B - HR)/pa, bb = BB/pa) %>%
filter(pa >= 100) %>%
group_by(playerID) %>%
summarize(mean_singles = mean(singles), mean_bb = mean(bb))
sum(bat_99_01$mean_singles > 0.2)
View(bat_99_01)
inner_join(bat_99_01, bat_02, by = "playerID")
bat_99_02 <- inner_join(bat_99_01, bat_02, by = "playerID")
View(bat_99_02)
bat_99_02 %>% cor(singles, mean_singles)
bat_99_02 %>% summarize(r = cor(mean_singles, singles)) %>% pull(r)
bat_99_02 %>% summarize(r = cor(mean_bb, bb)) %>% pull(r)
bat_99_02 %>% ggplot(aes(singles, mean_singles)) + geom_point()
bat_99_02 %>% ggplot(aes(bb, mean_bb)) + geom_point()
lm(singles ~ mean_singles data = bat_99_02)
lm(singles ~ mean_singles, data = bat_99_02)
lm(bb ~ mean_bb, data = bat_99_02)
?do
dat <- Teams %>% filter(yearID %in% 1961:2001) %>%
mutate(HR = round(HR/G, 1),
BB = BB/G,
R = R/G) %>%
select(HR, BB, R) %>%
filter(HR >= 0.4 & HR<=1.2)
dat2 <- dat %>% group_by(HR)
View(dat2)
View(dat)
lm (R ~ BB, data = dat2)
dat %>% do(fit2 = lm(R ~ BB, data = .))
library(broom)
set.seed(1, sample.kind = "Rounding") # if you are using R 3.6 or later
galton <- GaltonFamilies %>%
group_by(family, gender) %>%
sample_n(1) %>%
ungroup() %>%
gather(parent, parentHeight, father:mother) %>%
mutate(child = ifelse(gender == "female", "daughter", "son")) %>%
unite(pair, c("parent", "child"))
galton %>% group_by(heights)
galton %>% group_by(pair)
View(galton)
galton %>% group_by(pair) %>% filter(pair == "father_daughter")
galton %>% group_by(pair) %>% filter(pair == "mother_son")
galton %>%
group_by(pair) %>%
summarize(n = n())
galton %>% group_by(pair) %>% summarize(r = cor(parentHeight, childHeight)) %>% pull(r)
galton %>% group_by(pair) %>% summarize(r = cor(parentHeight, childHeight))
galton %>%
group_by(pair) %>%
do(tidy(lm(childHeight ~ parentHeight, data = .), conf.int = T))
galton_grouped <- galton %>% group_by(pair) %>% do(tidy(lm(childHeight ~ parentHeight, data = .), conf.int = T))
View(galton_grouped)
67*0.381+44.878
68*0.381+44.878
fit <- Teams %>%
filter(yearID == 1971) %>%
mutate(BB = BB/G, HR = HR/G,  R = R/G) %>%
lm(R ~ BB + HR, data = .)
tidy(fit, conf.int = TRUE)
bat_71 <- tidy(fit, conf.int = TRUE)
View(bat_71)
fit3 <- Teams %>%
+     filter(yearID %in% 1961:2018) %>%
+     mutate(BB = BB/G, HR = HR/G,  R = R/G) %>%
+     lm(R ~ BB + HR, data = .)
> tidy(fit3, conf.int = TRUE)
Q10 <- Teams %>% filter(yearID %in% 1961:2018) %>% mutate(BB = BB/G, HR = HR/G,  R = R/G) %>% group_by(yearID) %>% do(lm(R ~ HR + BB, data = .))
Q10 <- Teams %>% filter(yearID %in% 1961:2018) %>% mutate(BB = BB/G, HR = HR/G,  R = R/G) %>% group_by(yearID) %>% do(tidy(lm(R ~ HR + BB, data = .)))
View(Q10)
Q10 %>% filter(term == "BB") %>% ggplot(aes(yearID, estimate)) + geom_point()
res <- Teams %>%
filter(yearID %in% 1961:2018) %>%
group_by(yearID) %>%
do(tidy(lm(R ~ BB + HR, data = .))) %>%
ungroup()
res %>%
filter(term == "BB") %>%
ggplot(aes(yearID, estimate)) +
geom_point() +
geom_smooth(method = "lm")
lm(BB ~ yearID, data = Q10)
lm(BB ~ yearID, data = res)
lm(estimate ~ yearID, data = res)
predict(lm(estimate ~ yearID, data = res))
?lm
Q11 <- Teams %>% filter(yearID %in% 1961:2018) %>%group_by(yearID) %>% do(tidy(lm(R ~ BB + HR, data = .))) %>% filter(term == "BB") %>% lm(estimate ~ yearID, data = .)
View(Q11)
lm(estimate ~ yearID, data = res)
View(res)
Q11 res %>% filter(term == "BB") %>% lm(estimate ~ yearID, data = .)
Q11 <- res %>% filter(term == "BB") %>% lm(estimate ~ yearID, data = .)
View(Q11)
Q11
summary(Q11)
Teams_small <- Teams %>%
filter(yearID %in% 1961:2001) %>%
mutate(avg_attendance = attendance/G)
lm(avg_attendance ~ R, data = Teams_small)
lm(avg_attendance ~ HR, data = Teams_small)
mutate(Teams_small, R_per_game = R/G, HR_per_game = HR/G)
Teams_small <- mutate(Teams_small, R_per_game = R/G, HR_per_game = HR/G)
lm(avg_attendance ~ HR_per_game, data = Teams_small)
lm(formula = avg_attendance ~ R_per_game, data = Teams_small)
lm(average_attendance ~ W, data = Teams_small)
lm(avg_attendance ~ W, data = Teams_small)
lm(avg_attendance ~ yearID, data = Teams_small)
lm(avg_attendance ~ W + R_per_game, data = Teams_small)
cor(Teams_small$W, Teams_small$R_per_game)
cor(Teams_small$W, Teams_small$HR_per_game)
Teams_strat <- Teams_small %>% mutate(win_strat = round(W/10, digits = 0)) %>% filter(win_strat %in% 5:10 & n >= 20)
Teams_strat <- Teams_small %>% mutate(win_strat = round(W/10, digits = 0)) %>%
Teams_strat <- Teams_small %>% mutate(win_strat = round(W/10, digits = 0))
Teams_strat <- Teams_small %>% mutate(win_strat = round(W/10, digits = 0))
View(Teams_strat)
Teams_strat <- Teams_strat %>% filter(win_strat >= 5 & <= 10 )
Teams_strat <- Teams_strat %>% filter(win_strat >= 5 & win_strat <= 10)
Teams_strat <- Teams_strat %>% group_by(teamID) %>% filter(n() >= 20)
Teams_strat %>% filter(win_strat == 8) %>% nrow()
Teams_strat <- Teams_strat %>% group_by(teamID)
Teams_strat <- Teams_strat %>% group_by(teamID) %>% filter(n() >= 20)
Teams_strat <- Teams_strat %>% group_by(name) %>% filter(n() >= 20)
?group_by()
Teams_strat %>% filter(win_strat == 8) %>% nrow()
Teams_strat <- Teams_small %>% mutate(win_strat = round(W/10, digits = 0)) %>% group_by(teamID) %>% filter(win_strat >= 5 & <= 10 )
Teams_strat <- Teams_small %>% mutate(win_strat = round(W/10, digits = 0)) %>% group_by(teamID) %>% filter(win_strat >= 5 & win_strat <= 10 )
Teams_strat <- Teams_small %>% mutate(win_strat = round(W/10, digits = 0)) %>% group_by(teamID) %>% filter(n() >= 20) %>% filter(win_strat >= 5 & win_strat <= 10)
eight_strat <- Teams_strat %>% filter(win_strat == 8) %>% filter(n() >= 20)
View(eight_strat)
eight_strat <- Teams_strat %>% filter(win_strat == 8)
eight_strat <- Teams_strat %>% filter(win_strat == 8) %>% filter(n(teamID) >= 20)
eight_strat <- Teams_strat %>% filter(win_strat == 8) %>% filter(n(teamID()) >= 20)
eight_strat <- Teams_strat %>% filter(win_strat == 8) %>% filter(teamID, n() >= 20)
eight_strat <- Teams_strat %>% filter(win_strat == 8) %>% group_by(teamID) %>% filter(n() >= 20)
View(Teams_strat)
Teams_strat <- Teams_small %>% mutate(win_strat = round(W/10, digits = 0)) %>% filter(win_strat >= 5 & win_strat <= 10) %>% group_by(teamID) %>% filter(n() >= 20)
eight_strat <- Teams_strat %>% filter(win_strat == 8) %>% group_by(teamID) %>%
l
eight_strat <- Teams_strat %>% filter(win_strat == 8) %>% group_by(teamID)
eight_strat <- Teams_strat %>% filter(win_strat == 8 & W >= 20)
Teams_strat <- Teams_small %>% mutate(win_strat = round(W/10, digits = 0)) %>% filter(win_strat >= 5 & win_strat <= 10)
eight_strat <- Teams_strat %>% filter(win_strat == 8) %>% nrow()
eight_strat <- Teams_strat %>% filter(win_strat == 8)
eight_strat %>% group_by(win_strat) %>% lm(avg_attendance ~ R_per_game, data = .)
Teams_strat %>% group_by(win_strat) %>% lm(avg_attendance ~ R_per_game, data = .)
Teams_strat %>% group_by(win_strat)
Teams_strat <- Teams_small %>% mutate(win_strat = round(W/10, digits = 0)) %>% filter(win_strat >= 5 & win_strat <= 10)
Teams_strat %>%
ggplot(aes(R_per_game, avg_attendance)) +
geom_point(alpha = 0.5) +
geom_smooth(method = "lm") +
facet_wrap( ~ win_strat)
Teams_strat %>%
ggplot(aes(HR_per_game, avg_attendance)) +  geom_point(alpha = 0.5) + geom_smooth(method = "lm") + facet_wrap( ~ win_strat)
Teams_strat <- Teams_small %>% mutate(win_strat = round(W/10, digits = 0)) %>% filter(win_strat >= 5 & win_strat <= 10)
> Teams_strat %>% ggplot(aes(R_per_game, avg_attendance)) +  geom_point(alpha = 0.5) + geom_smooth(method = "lm") + facet_wrap( ~ win_strat)
Teams_strat %>% ggplot(aes(R_per_game, avg_attendance)) +  geom_point(alpha = 0.5) + geom_smooth(method = "lm") + facet_wrap( ~ win_strat)
lm(avg_attendance ~ R_per_game + HR_per_game + W + yearID, data = Teams_small)
?fit
fit <- lm(avg_attendance ~ R_per_game + HR_per_game + W + yearID, data = Teams_small)
?predict
predict(fit, newdata = c(5, 1.2, 80, 2002))
newlist <- c(5, 1.2, 80, 2002)
class(newlist)
predict(fit, newdata = newlist)
data.frame(c(5, 1.2, 80, 2002))
data.frame(
speed = c(12, 19, 24)
)
newlist1 <- data.frame(R_per_game = 5, HR_per_game = 1.2, W = 80, yearID = 2002)
View(newlist1)
predict(fit, newdata = newlist1)
newlist2 <- data.frame(R_per_game = 5, HR_per_game = 1.2, W = 80, yearID = 1960)
predict(fit, newdata = newlist2)
predict(fit, Teams)
Teams %>% mutate(R_per_game = R/G, HR_per_game = HR/G, avg_attendance = attendance/G) %>% predict(fit, newdata = .)
Teams %>% mutate(R_per_game = R/G, HR_per_game = HR/G, avg_attendance = attendance/G) %>% filter(yearID == 2002) %>% predict(fit, newdata = .)
Teams %>% mutate(R_per_game = R/G, HR_per_game = HR/G, avg_attendance = attendance/G) %>% filter(yearID == 2002) %>% mutate(predicted = predict(fit, newdata = .)) %>% summarize(r = cor(avg_attendance, predicted))
library(broom)
install.packages("pROC")
install.packages(c('spData', 'spDataLarge', 'tmap', 'leaflet'))
library(sf)
library(raster)
library(dplyr)
library(tmap)
library(leaflet)
library(ggplot2)
library(raster)
results <- train %>% transmute(
actual = num_tot_energy_heat,
predicted = y_hat,
error = actual-predicted,
rmse = sqrt(error^2)
)
library(rpart.plot)
# Tosin's code for prepping, training, and testing
# SKor Data
setwd("~/R/UCL/BENV0091/EDA-Project/EDA-Project/R")
library(tidyverse)
library(rpart) # for regression trees
library(rpart.plot)
library(caret) # for splitting into train and test sets
df <- read_csv("../data/sKor_data_tot_v02.csv")
excluded_vars <- c("X1", "id_hs", "id_hh") #removing IDs so I can comfortably use (.)
df <- df %>% dplyr::select(-excluded_vars)
# r said to use `all_of(excluded_vars)` to silence warning but
# it worked sooo
#changing all cat_ variables to factors
df <- df %>% mutate(across(starts_with("cat"), as.factor))
set.seed(123)
train_index <- createDataPartition(df$num_tot_energy_heat, times = 1,
p = 0.7, list = FALSE)
#meant to create partition on the y values, as it stratifies that data
train <- df %>% slice(train_index)
test <- df %>% slice(-train_index)
#rpart tuning parameters: cp, minsplit, minbucket, maxdepth
#see rpart.control for explanations
#cp - most important - decides no. of splits in a tree
# and therefore affects the rest of them i guess
#maxdepth - maximum depth of any node of the final tree (meaning?)
#minbucket is automatically minsplit/3
#cross validation to pick the best tuning parameters
train_rpart <- train(num_tot_energy_heat ~ .,
method = "rpart",
tuneGrid = data.frame(cp = seq(0, 0.05, len = 25)),
trControl = trainControl(method = "repeatedcv",
number = 10),
data = train)
best_cp <- train_rpart$bestTune
#bestTune before = 0.00625 (before change to factors)
#then = 0.008333333[5] RMSE 5026
#currently = 0.0041666 [3] RMSE 4927.586 (after cross validation)
#very rudimentary way of sourcing the row with the best cp but oh well
train_rpart[["results"]][3,]
y_hat <- predict(train_rpart, newdata = train, type = "raw")
#use vector if its a regression tree, and class if its a classification tree
# also: thought i could just extract final model from caret and use for predications
# but apparently not? caret_fit <- train_rpart$finalModel
# use full trian_rpart
results <- train %>% transmute(
actual = num_tot_energy_heat,
predicted = y_hat,
error = actual-predicted
)
#right now, very high errors lol
#plotting the decision tree
plot(train_rpart$finalModel, margin = 0.1)
text(train_rpart$finalModel, cex = 0.75)
rpart.plot(train_rpart)
rpart.plot(train_rpart$finalModel)
?**
results <- train %>% transmute(
actual = num_tot_energy_heat,
predicted = y_hat,
error = actual-predicted,
mse = mean(error^2),
rmse = sqrt(mse),
mae = mean(actual-predicted)
)
View(results)
#using rpart plot gives a much better tree but low quality
rpart.plot(train_rpart$finalModel, fallen.leaves = FALSE)
#using rpart plot gives a much better tree but low quality
prp(train_rpart$finalModel, compress = FALSE)
#using rpart plot gives a much better tree but low quality
prp(train_rpart$finalModel, compress = FALSE, tweak = 1.5)
#using rpart plot gives a much better tree but low quality
rpart.plot(train_rpart$finalModel, tweak = 1.5,
box.palette = "Purples")
#using rpart plot gives a much better tree but low quality
rpart.plot(train_rpart$finalModel, tweak = 1.5,
box.palette = "Purples",
fallen.leaves = FALSE)
#using rpart plot gives a much better tree but low quality
rpart.plot(train_rpart$finalModel, tweak = 1.5,
box.palette = "Purples",
type = 3,
fallen.leaves = FALSE)
#using rpart plot gives a much better tree but low quality
rpart.plot(train_rpart$finalModel, tweak = 2,
box.palette = "Purples",
type = 3,
fallen.leaves = FALSE)
#using rpart plot gives a much better tree but low quality
rpart.plot(train_rpart$finalModel, tweak = 2.5,
box.palette = "Purples",
type = 3,
fallen.leaves = FALSE)
#using rpart plot gives a much better tree but low quality
rpart.plot(train_rpart$finalModel, tweak = 4,
box.palette = "Purples",
type = 3,
fallen.leaves = FALSE)
#using rpart plot gives a much better tree but low quality
rpart.plot(train_rpart$finalModel, tweak = 3,
box.palette = "Purples",
type = 3,
fallen.leaves = FALSE)
#using rpart plot gives a much better tree but low quality
rpart.plot(train_rpart$finalModel, tweak = 3,
box.palette = "Purples",
type = 0,
fallen.leaves = FALSE)
#using rpart plot gives a much better tree but low quality
rpart.plot(train_rpart$finalModel, tweak = 1.6,
box.palette = "Purples",
type = 0,
fallen.leaves = FALSE)
#using rpart plot gives a much better tree but low quality
rpart.plot(train_rpart$finalModel, tweak = 1.6,
box.palette = "Purples",
type = 0,
fallen.leaves = FALSE,
extra = 0)
#using rpart plot gives a much better tree but low quality
rpart.plot(train_rpart$finalModel, tweak = 1.6,
box.palette = "Purples",
type = 0,
#fallen.leaves = FALSE,
extra = 0)
#using rpart plot gives a much better tree but low quality
rpart.plot(train_rpart$finalModel, tweak = 1.6,
box.palette = "Purples",
type = 0,
fallen.leaves = FALSE,
extra = 0)
#using rpart plot gives a much better tree but low quality
rpart.plot(train_rpart$finalModel, tweak = 1.6,
box.palette = "Purples",
type = 1,
fallen.leaves = FALSE,
extra = 0)
#using rpart plot gives a much better tree but low quality
rpart.plot(train_rpart$finalModel, tweak = 1.8,
box.palette = "Purples",
type = 1,
fallen.leaves = FALSE,
extra = 0)
#plotting errors
results %>% ggplot(aes(actual,predicted)) + geom_abline(intercept = 0, slope = 1))
#plotting errors
results %>% ggplot(aes(actual,predicted)) + geom_abline(intercept = 0, slope = 1)
geom_abline(intercept = 0, slope = 1)
#plotting errors
results %>% ggplot(aes(actual,predicted)) +
geom_point() +
geom_abline(intercept = 0, slope = 1)
#plotting errors
results %>% ggplot(aes(actual,predicted)) +
geom_point() +
geom_abline(intercept = min(actual), slope = 1)
#plotting errors
results %>% ggplot(aes(actual,predicted)) +
geom_point() +
geom_abline(intercept = min(results$actual), slope = 1)
#plotting errors
results %>% ggplot(aes(actual,predicted)) +
geom_point() +
geom_abline(intercept = min(results$predicted), slope = 1)
#plotting errors
results %>% ggplot(aes(actual,predicted)) +
geom_point() +
geom_abline(intercept = min(results$predicted), slope = 1) +
ylim(min(results$predicted)) +
xlim(min(results$actual))
#plotting errors
results %>% ggplot(aes(actual,predicted)) +
geom_point() +
geom_abline(intercept = min(results$predicted), slope = 1) +
ylim(min(results$predicted), max(results$predicted)) +
xlim(min(results$actual), max(results$actual))
#plotting errors
results %>% ggplot(aes(actual,predicted)) +
geom_point() +
#geom_abline(intercept = min(results$predicted), slope = 1) +
ylim(min(results$predicted), max(results$predicted)) +
xlim(min(results$actual), max(results$actual))
#plotting errors
results %>% ggplot(aes(actual,predicted)) +
geom_point() +
geom_abline(intercept = min(results$predicted), slope = 1) +
ylim(min(results$predicted), max(results$predicted)) +
xlim(min(results$actual), max(results$actual))
min(results$actual)
min(results$predicted)
View(results)
results %>% ggplot(aes(actual,errors)) +
geom_point()
results %>% ggplot(aes(actual,error)) +
geom_point()
