trellis.par.set(caretTheme())
library(tidyverse)
library(caret)
library(rpart)
library(broom)
library(rpart)
library(randomForest)
library(ranger)
library(e1071)
train_full <- read_csv('C:/Users/Admin/EDA-Project/data/sKor_train_data.csv')
train_full <- train_full %>% mutate(across(starts_with("cat"), as.factor))
train_sample <- sample(nrow(train_full), 0.02*nrow(train_full), replace = FALSE)
training_sample<- train_full[train_sample,]
#cross validation with validation data
#ensure you discuss that random forest isnnot intutative.
train_sample <- sample(nrow(train_full), 0.02*nrow(train_full), replace = FALSE)
training_sample<- train_full[train_sample,]
#set sequence for the 3 hyper parameters
num_tree<- seq(250,2000,50)
min_nodes <- seq(2,10,2)
m_try <- seq(2,18,2)
split_rule <- c("variance", "extratrees", "maxstat")
#add all hyparemeters to one grid
ranger_grid <-  expand.grid( splitrule=split_rule,
#num.trees = num_tree,
mtry  = m_try,
min.node.size = min_nodes)
#set the train cross validation
tr_Control <- trainControl(method = "cv",
number = 10,
search = "grid")
#traim mpodel with hypeparameters using grid serch and 10 fold cross validation
set.seed(123)
ranger_fit <- train(num_tot_energy_heat ~ ., data = training_sample,
method = "ranger",
trControl = tr_Control,
verbose = FALSE,
tuneGrid = ranger_grid)
#best model from cv
# ranger_best <- best(ranger_fit$results, metric = "RMSE",
#                        maximize = TRUE)
# ranger_fit$results[ranger_best, 1:6]
#
# #best model based on results
# ranger_test <- ranger(num_tot_energy_heat~., data=training_sample,splitrule="extratrees",
#                          #num.trees = num_tree,
#                         mtry  = 16,
#                         min.node.size = 4,  scale.permutation.importance = TRUE,
#   local.importance = TRUE)
#
# importance(ranger_test)
#ranger random forest with no hyperparmeters
#ranger_basic <- ranger(num_tot_energy_heat~., data=training_sample)
#cross validation with validation data
#ensure you discuss that random forest isnnot intutative.
train_sample <- sample(nrow(train_full), 0.02*nrow(train_full), replace = FALSE)
training_sample<- train_full[train_sample,]
#set sequence for the 3 hyper parameters
num_tree<- seq(250,2000,50)
min_nodes <- seq(2,10,2)
m_try <- seq(2,18,2)
split_rule <- c("variance", "extratrees", "maxstat")
#add all hyparemeters to one grid
ranger_grid <-  expand.grid( splitrule=split_rule,
#num.trees = num_tree,
mtry  = m_try,
min.node.size = min_nodes)
#set the train cross validation
tr_Control <- trainControl(method = "cv",
number = 10,
search = "grid")
#traim mpodel with hypeparameters using grid serch and 10 fold cross validation
set.seed(123)
ranger_modelfit <- train(num_tot_energy_heat ~ ., data = train_full,
method = "ranger",
trControl = tr_Control,
verbose = FALSE,
tuneGrid = ranger_grid)
#best model from cv
# ranger_best <- best(ranger_fit$results, metric = "RMSE",
#                        maximize = TRUE)
# ranger_fit$results[ranger_best, 1:6]
#
# #best model based on results
# ranger_test <- ranger(num_tot_energy_heat~., data=training_sample,splitrule="extratrees",
#                          #num.trees = num_tree,
#                         mtry  = 16,
#                         min.node.size = 4,  scale.permutation.importance = TRUE,
#   local.importance = TRUE)
#
# importance(ranger_test)
#ranger random forest with no hyperparmeters
#ranger_basic <- ranger(num_tot_energy_heat~., data=training_sample)
View(ranger_modelfit)
ranger_best_model <- best(ranger_modelfit$results, metric = "RMSE",
maximize = TRUE)
ranger_modelfit$results[ranger_best_model, 1:6]
m_try <- seq(4,18,2)
#cross validation with validation data
#ensure you discuss that random forest isnnot intutative.
train_sample <- sample(nrow(train_full), 0.02*nrow(train_full), replace = FALSE)
training_sample<- train_full[train_sample,]
#set sequence for the 3 hyper parameters
num_tree<- seq(250,2000,50)
min_nodes <- seq(2,10,2)
m_try <- seq(4,18,2)
split_rule <- c("variance", "extratrees", "maxstat")
#add all hyparemeters to one grid
ranger_grid <-  expand.grid( splitrule=split_rule,
#num.trees = num_tree,
mtry  = m_try,
min.node.size = min_nodes)
#set the train cross validation
tr_Control <- trainControl(method = "cv",
number = 10,
search = "grid")
#traim mpodel with hypeparameters using grid serch and 10 fold cross validation
set.seed(123)
ranger_modelfit <- train(num_tot_energy_heat ~ ., data = train_full,
method = "ranger",
trControl = tr_Control,
verbose = FALSE,
tuneGrid = ranger_grid)
#best model from cv
ranger_best_model <- best(ranger_modelfit$results, metric = "RMSE",
maximize = TRUE)
ranger_modelfit$results[ranger_best_model, 1:6]
#best model based on results
# ranger_test <- ranger(num_tot_energy_heat~., data=training_sample,splitrule="extratrees",
#                          #num.trees = num_tree,
#                         mtry  = 16,
#                         min.node.size = 4,  scale.permutation.importance = TRUE,
#   local.importance = TRUE)
#
# maxstat	2	10	5139.151
# importance(ranger_test)
# ranger random forest with no hyperparmeters
#ranger_basic <- ranger(num_tot_energy_heat~., data=training_sample)
ranger_model_best <- ranger(num_tot_energy_heat~., data=training_sample,splitrule="maxstat",
mtry  = 4,
min.node.size = 10)
predictions <- predict(ranger_model_best, train_full, type = 'response')
View(predictions)
predictions
train_preds <- train_full%>%
transmute(
actual = value_max,
predicted_ranger=predictions)
train_preds <- train_full%>%
transmute(
actual = num_tot_energy_heat~.,
predicted_ranger=predictions)
train_preds <- train_full%>%
transmute(
actual = num_tot_energy_heat,
predicted_ranger=predictions)
train_preds <- train_full%>%
transmute(
actual = num_tot_energy_heat,
predicted_ranger=predict(ranger_model_best, .))
train_preds <- train_full%>%
transmute(
actual = num_tot_energy_heat,
predicted_ranger=predictions)
predictions
predictions_tibble <- tibble(predictions)
train_preds <- train_full%>%
transmute(
actual = num_tot_energy_heat,
predicted_ranger=predictions)
predictions$predictions
train_preds <- train_full%>%
transmute(
actual = num_tot_energy_heat,
predicted_ranger=predictions$predictions)
View(train_preds)
View(train_preds)
final_predictions <- train_preds %>% mutate(rmse=rmse(actual,predicted_ranger))
rmse <- function(actual, predicted){
mse <- mean((actual - predicted) ** 2)
return(sqrt(mse))
}
final_predictions <- train_preds %>% mutate(rmse=rmse(actual,predicted_ranger))
View(final_predictions)
View(final_predictions)
final_predictions <- train_preds %>% mutate( mse=mse(actual,predicted_ranger),
mae=mse(actual,predicted_ranger),                            )
mse <- function(actual, predicted){
mse <- mean((actual - predicted) ** 2)
return((mse))
}
mae <- function(actual, predicted){
mae <- mean((actual - predicted))
return((mae))
}
final_predictions <- train_preds %>% mutate( mse=mse(actual,predicted_ranger),                          mae=mse(actual,predicted_ranger))
View(final_predictions)
final_predictions <- train_preds %>% mutate(
rmse=rmse(actual,predicted_ranger),
mse=mse(actual,predicted_ranger),                          mae=mse(actual,predicted_ranger))
View(final_predictions)
final_predictions <- train_preds %>% mutate(
rmse=rmse(actual,predicted_ranger),
mse=mse(actual,predicted_ranger),                          mae=mae(actual,predicted_ranger))
#visualise to compare the different models
trellis.par.set(caretTheme())
plot(ranger_modelfit)
#
ggplot(ranger_modelfit)
plot(predicted_range,actual,
xlab="predicted",ylab="actual")
ranger_modelfit$bestTune
ranger_modelfit$results[ranger_best_model, 1:6]
trellis.par.set(caretTheme())
plot(ranger_modelfit)
View(ranger_grid)
View(ranger_grid)
View(train_full)
View(train_full)
